### 3.5.2. Unicode


在很久以前, 世界比较简单的, 起码计算机就只有一个ASCII字符集: 美国信息交换标准代码. ASCII, 更准确地说是美国的ASCII, 使用 7bit 来表示 128 个字符: 包含英文字母的大小写, 数字, 各种标点符号和设置控制符. 对于早期的计算机程序, 这些足够了, 但是这也导致了世界上很多其他地区的用户无法直接使用自己的书写系统. 随着互联网的发展, 混合多种语言的数据变了很常见. 如何有效处理这些包含了各种语言的丰富多样的数据呢?

答案就是使用Unicode(unicode.org), 它收集了这个世界上所有的书写系统, 包括重音符号和其他变音符号, 制表符和回车符, 还有很多神秘符号, 每个符号都分配一个Unicode码点, Unicode码点对应Go语言中的rune类型.

第八版本的Unicode标准收集了超过120,000个字符, 涵盖超过100种语言. 这些在计算机程序和数据中是如何体现的那? 通用的表示一个Unicode码点的数据类型是int32, 也就是Go语言中rune对应的类型; 它的同义词rune符文正是这个意思.

我们可以将一个符文序列表示为一个int32序列. 这种编码方式叫UTF-32或UCS-4, 每个Unicode码点都使用同样的大小32bit来表示. 这种方式比较简单统一, 它会浪费很多存储空间, 因为大数据计算机可读的文本是ASCII字符, 本来每个ASCII字符只需要8bit或1字节就能表示. 即使是常用的字符也远少于65,536个, 也就是说用16bit编码方式就能表达常用字符. 但是, 还有更好的编码方法吗?




